[TOC]

# High performance Notes

## Java Performance (2012)- Charlie Hunt & Binu John
### The Performance Attributes

* Throughput
* Latency
* Footprint: the amount of memory a garbage collector requires

A performance improvement for one of these attributes almost always is at the expense of one or both of the other attributes  

## 认清性能问题
[认清性能问题](https://mp.weixin.qq.com/s?__biz=MzAxMTEyOTQ5OQ==&mid=2650610655&idx=1&sn=4f38ef56ff57054ab9745b0725351159&scene=23&srcid=0824IUyLIot4dXFjXdW4wK0I#rd) 陈天 mindwind（译） 瞬息之间
[Thinking Clearly about Performance](https://queue.acm.org/detail.cfm?id=1854041) Cary Millsap, Method R Corporation

### 响应时间 VS. 吞吐量
通常来讲，响应时间和吞吐量是一个倒数关系（响应时间越长吞吐量越低），但这并不确切。 实际情况更微妙、复杂一些。
### 百分比指标
描述使用百分比指标: 在大于 99％ 的情况下响应时间要少于 1 秒，并且能支持 10 分钟内持续不低于 1000 的吞吐量
###性能剖析
即对响应时间的表格化分解，按响应时长倒序排列.   
性能剖析指出了哪些代码花费了你的时间，也许更重要的是告诉你哪些代码并没有花费太多时间
### 阿姆达尔定律
吉恩·阿姆达尔（Gene Amdahl） 1967 年:
> 系统中对某一部件采用更快执行方式所能获得的系统性能改进程度，取决于这种执行方式被使用的频率，或所占总执行时间的比例

所以如果你尝试改进的部分只占总响应间的 5％，那么对总响应时间的提高最多不会超过 5％。这意味着你改进的部分在性能剖析列表中排位越高（假设它们按倒序排列），你获得的收益就越大。  
但这并不意味着你一定要按照性能剖析列表的顺序从高到低进行改进，这里你还需要考虑改进的成本问题。

## I/O

I/O有内存I/O,网络I/O和磁盘I/O,在讨论Web站点性能时很少提及内存I/O,国为相比后两种I/O操作,内存I/O的速度已经够快了,性能瓶颈往往并不在于内存I/O.  
以文件I/O为例,一个I/O读过程: 数据从磁盘(网卡) -> 内核缓冲区 -> 用户内存. 同步与异步的区别主要在于数据从内核缓冲区 -> 用户内存这个过程需不需要用户进程等待.

* 同步阻塞
* 同步非阻塞
* I/O多路复用 select/poll/epoll
* 信号驱动 sigio
* 异步非阻塞

### 阻塞与非阻塞,同步与异步
阻塞和非阻塞是指当前进程访问的数据如果尚未就绪,进程是否需要等待,简单说相当于函数内部的实现区别,即未就绪时是直接返回还是等待就绪  
同步和异步是指访问数据的机制  
	同步指主动请求并等待I/O操作完毕的方式,当数据就绪后在读写的时候必须阻塞.  
	异步指主动请求数据后便可以继续处理其他任务,随后等待IO操作完毕的通知,这可以使进程在数据读写时也不发生阻塞.

### 同步阻塞I/O
同步阻塞I/O是指当进程调用某些涉及I/O操作的系统调用或库函数时,比如accept(),send(),recv()等,进程便停下来,等待I/O操作完成后继续运行. 这是一种简单而有效的I/O模型,它可以和多进程结合起来有效地利用CPU资源,但是代价就是多进程的大量内存开销.  
进程实际等待时间 = 等待数据就绪 + 等待数据复制. 对于网络I/O来说,等待就绪的时间会更长.  

**在小吃城吃饭的例子** 在小吃城的小吃店里点了一个面条,然后等着做好,做好后吃完再继续逛街.这里的吃面条便是I/O操作,它要等厨师做面条,还要等自己把面条吃完.

### 同步非阻塞I/O
同步非阻塞I/O的调用不会等待数据的就绪,如果数据不可读或者不可写,它会立即告诉进程. 结合反复轮询来尝试数据是否就绪,防止进程被阻塞,最大的好处便在于可以在一个进程里同时处理多个I/O操作.  
但多次轮询会花费大量的CPU时间,使得进程处于忙碌等待状态

**在小吃城吃饭的例子** 回到买面条的故事,假如你不甘心坐着等面条,想去逛街,可又担心做好后没及时取,所以你逛一会儿便回去看看面条是否做好,往返了很多次,最后及时吃上了面条,但是却累的气喘吁吁

非阻塞I/O一般只针对网络I/O有效,只要在socket的选项设置中使用O_NONBLOCK即可,这样对于该socket的send()或recv()便采用非阻塞方式. 值得注意的是,对于磁盘I/O,非阻塞I/O并不产生效果.

#### 多路I/O就绪通知
多路I/O就绪通知提供了大量文件描述符(File Descriptor, FD)就绪检查的高效方案,它允许进程通过一种方法来同时监视所有FD,并可以获得所有就绪的FD,然后只针对这些FD进行数据访问.

**在小吃城吃饭的例子** 假如你不止买了一份面条,还在其他几个小吃店买了饺子,粥等.这些东西都需要时间来制作.在同步非阻塞I/O模型中,你要轮流不停地去各个小吃店询问进度.现在引入多路I/O就绪通知后,小吃管理处给大厅安装了一块电子屏幕,以后所有小吃店的食物做好后,都会显示在屏幕上,你只需要间隔性地看看大屏幕就可以了,也许你还可以同时逛逛附近的商店,在不远处也可以看到大屏幕.

I/O就绪通知只是快速获得就绪的FD,当得知数据就绪后,就访问数据本身而言,仍然需要选择阻塞或者非阻塞的访问方式,以防止任何意外的等待阻塞整个进程.  
I/O复用的实现方式主要有select,poll和epoll

#### select/poll
select和poll的原理基本相同:
* 注册待侦听的FD
* 每次调用都去检查所有FD的状态,当有一个或者多个FD就绪时就返回
* 返回结果中包括已就绪和未就绪的FD
select的一个缺点在于单个进程能监视的FD的数量存在最大限制,在Linux上一般为1024,不过可以通过修改宏定义甚至重新编译内核的方式提升这一限制.  
poll没有最大FD数量的限制.  
poll和select共同具有的一个很大的缺点是包含大量FD的数组被整体复制于用户态和内核地址空间之间,开销会随着FD数量增多而线性增大.  
优点: select和poll将就绪的FD告诉进程后,如果没有对其进行I/O操作,那么下次调用select或poll的时候将再次报告这些FD,所以它们一般不会丢失就绪的消息,这种方式称为**水平触发(Level Triggered)**  

#### 信号驱动 SIGIO
Linux 2.4提供了SIGIO,它通过实时信号(Real Time Signal)来实现select/poll的通知方法,但它们的不同在于,select/poll告诉我们哪些FD是就绪的,一直到我们读写它之前,每次select/poll都会告诉我们;而SIGIO则是告诉我们哪些FD刚刚变为就绪状态,它只说一遍,如果我们没有采取行动,那么它将不会再次告知,这种方式称为**边缘触发(Edge Triggered)**. 缺点是容易发生事件丢失.  
SIGIO几乎是Linux 2.4下性能最好的多路I/O就绪通知方法.

#### epoll
epoll的出现解决了select/poll的缺点:
1. 基于事件驱动的方式,避免了每次都要把所有FD都扫描一遍
2. `epoll_wait`只返回就绪的文件标识符
3. `epoll`使用nmap内存映射技术避免了内存复制开销  
4. epoll的FD数量上限是操作系统的最大文件句柄数目,这个数据一般和内存有关,通常远大于1024
5. epoll默认使用水平触发,通过相应选项可以使用边缘触发.

目前,epoll是Linux 2.6下最高效的I/O复用方式,也是Nginx,Node的I/O实现方式.

**在小吃城吃饭的例子** 虽然有了电子屏幕,但是显示的内容是所有餐品的状态,包括正在制作的和已经做好的,这显然造成了阅读上的麻烦,就好像select/poll每次返回所有监视的文件描述符一样.如果能只显示做好的餐品,那该多好,随后小吃城管理处改进并实现了这一点.这就像/dev/poll一样只告知就绪的文件描述符.在显示做好的餐点时,如果只显示一次,而不管你有没有看到,这就相当于边缘触发,而如果在你领取餐点之前,每次都显示,就相当于水平触发.  
但尽管这样,一旦你走的比较远,就还得花时间走到小吃城去看电子屏幕,能不能让你更加轻松地获得通知呢?管理处这次采用了手机短信通知的方法,你只需要到管理处注册后,便可以在餐点就绪时及时收到短信通知,这类似于epoll的事件机制.

#### 内存映射 Memory Mapping
Linux内核提供的一种访问磁盘文件的特殊方式,它可以将内存中某块地址空间和我们要指定的磁盘文件相关联,从而把我们对这块内存的访问转换为对磁盘文件的访问,这种技术称为内存映射.  
多数情况下,使用内存映射可以提高磁盘I/O的性能,像访问内存一样自由的访问文件.

#### 直接I/O
数据访问过程 磁盘 -> 内核缓冲区 -> 用户态内存空间
有一些应用(如数据库服务器)为了充分提高性能,希望绕过内核缓冲区,由自己在用户态空间实现并管理I/O缓冲区,包括缓存机制和写延迟机制等.

### 异步I/O 异步非阻塞
对比信号驱动IO，异步IO的主要区别在于：信号驱动由内核告诉我们何时可以开始一个IO操作(数据在内核缓冲区中)，而异步IO则由内核通知IO操作何时已经完成(数据已经在用户空间中)。  
异步IO又叫做事件驱动IO，在Unix中，POSIX1003.1标准为异步方式访问文件定义了一套库函数，定义了AIO的一系列接口。使用`aio_read`或者`aio_write`发起异步IO操作。使用`aio_error`检查正在运行的IO操作的状态。

**在小吃城吃饭的例子** 之前的就餐方式，到最后总是需要你自己去把饭菜端到餐桌。这下你也不耐烦了，于是就告诉老板，能不能饭好了直接端到你的面前或者送到你的家里(外卖)。这就是异步非阻塞IO了。  

### Java I/O
上文讲述了UNIX环境的五种IO模型。基于这五种模型，在Java中，随着NIO和NIO2.0(AIO)的引入，一般具有三种网络编程模型：BIO,NIO,AIO

#### BIO
BIO是一个典型的网络编程模型，是通常我们实现一个服务端程序的过程，步骤如下：
1. 主线程accept请求阻塞
2. 请求到达，创建新的线程来处理这个套接字，完成对客户端的响应。
3. 主线程继续accept下一个请求
这种模型有一个很大的问题是：当客户端连接增多时，服务端创建的线程也会暴涨，系统性能会急剧下降。因此，在此模型的基础上，类似于 tomcat的bio connector，采用的是线程池来避免对于每一个客户端都创建一个线程。有些地方把这种方式叫做伪异步IO(把请求抛到线程池中异步等待处理)。

#### NIO
JDK1.4开始引入了NIO类库，这里的NIO指的是Non-block IO，主要是使用Selector多路复用器来实现。Selector在Linux等主流操作系统上是通过epoll实现的。
NIO的实现流程，类似于select：
1. 创建ServerSocketChannel监听客户端连接并绑定监听端口，设置为非阻塞模式。
2. 创建Reactor线程，创建多路复用器(Selector)并启动线程。
3. 将ServerSocketChannel注册到Reactor线程的Selector上。监听accept事件。
4. Selector在线程run方法中无线循环轮询准备就绪的Key。
5. Selector监听到新的客户端接入，处理新的请求，完成TCP三次握手，建立物理连接。
6. 将新的客户端连接注册到Selector上，监听读操作。读取客户端发送的网络消息。
7. 客户端发送的数据就绪则读取客户端请求，进行处理。
相比BIO，NIO的编程非常复杂。

#### AIO
JDK1.7引入NIO2.0，提供了异步文件通道和异步套接字通道的实现，是真正的异步非阻塞I/O, 对应于Unix中的异步I/O。
1. 创建AsynchronousServerSocketChannel，绑定监听端口
2. 调用AsynchronousServerSocketChannel的accept方法，传入自己实现的CompletionHandler。包括上一步，都是非阻塞的
3. 连接传入，回调CompletionHandler的completed方法，在里面，调用AsynchronousSocketChannel的read方法，传入负责处理数据的CompletionHandler。
4. 数据就绪，触发负责处理数据的CompletionHandler的completed方法。继续做下一步处理即可。
5. 写入操作类似，也需要传入CompletionHandler。
其编程模型相比NIO有了不少的简化。

#### 对比
对比				|	同步阻塞IO	|	伪异步IO	|	NIO		|	AIO
----|---
客户端数目 IO线程	| 	1 : 1 		|	m : n	|	m : 1	|	m : 0
IO模型 			|	同步阻塞IO	|同步阻塞IO 	|同步非阻塞IO |异步非阻塞IO
吞吐量 			|	低 			|	中		| 	高		| 	高
编程复杂度 		| 	简单 		|	简单 	|非常复杂 	|	复杂


## 缓存
##### 缓存如何存储
##### 缓存命中率如何
##### 缓存过期策略如何设计
##### 分布式缓存设计

## 分布式多线程

## 如何应对并发
转自　曹政 caoz的梦呓
### [如何应对并发(1) - 关于数据索引](http://mp.weixin.qq.com/s?__biz=MzI0MjA1Mjg2Ng==&mid=400470606&idx=1&sn=eff5350f80190ad6e32659f434aac970&scene=0#wechat_redirect)

#### 经典案例1，大翻页问题
#### 经典案例2，积分排行问题

#### 如何评估SQL的执行开销
索引中遍历的记录越少，效率越高，遍历的记录越多，效率越差。 在慢查询日志或者explain分析中，一个重要的指标是 affected rows，（好像也有别的叫法，不查证了，大家应该能知道我说的是什么），这个就是索引遍历的记录说，我以前硬翻译叫做影响结果集，我后来看其他人写的数据库文档叫索引扫描行数，概念是一样的。

高性能ＭySQL
explain SQL
去数据库里，先show processlist;看到有疑问的SQL，去explain，然后set profiling=1

### [如何应对并发(2) - 请求合并及异步处理](http://mp.weixin.qq.com/s?__biz=MzI0MjA1Mjg2Ng==&mid=400480069&idx=1&sn=4119397d0e3b0444f04d25f76ecdfbe3&scene=0#wechat_redirect)

#### 并不是查询请求缓存化了系统效率就会提升
1、如果缓存命中率不高，可能反而是负担  
2、如果缓存计不合理，系统开销只会更高  
3、雪崩效应的风险  

#### 慢查询日志肯定是要看的
第一，看查询和更新的比例。
第二，看最多查询的数据表有哪些，最多更新的数据表有哪些。
第三，看最多查询的数据表最多查询的SQL是什么样子的，最多更新的数据表最多执行更新的SQL是怎样的，算出各自每秒的请求频率。
第四，关键分析，最多查询的SQL，基于同一主键查询的比例多不多（潜台词，可以缓存化）。最多更新的SQL，基于同一主键的更新的比例高不高（潜台词，可以合并请求，异步处理，当然必须根据具体业务诉求再核对一遍）
首先用眼睛看日志找规律，其次基于规律用grep 来统计。 然后把内容整理后，询问相关的程序员，每条问题SQL的业务逻辑是什么，然后毕竟还是要让他们一线的程序员来评估业务逻辑上这些操作是否可以合并，缓存，或者异步处理

### [如何应对并发(3) - 需求裁剪](http://mp.weixin.qq.com/s?__biz=MzI0MjA1Mjg2Ng==&mid=400516974&idx=1&sn=66a65b0900a8a410b7268d4b9c7bbddb&scene=0#wechat_redirect)

#### 案例1：搜索大翻页问题，还记得我提过的这个搜索翻页越多，负载越高的问题么。
请问，  
淘宝搜索一个关键词，最多翻多少页？百度呢？google呢？  
你们自行测试一下，这些巨头给出的搜索结果条目数，我跟你们实话说，都是估算值，最大翻页数，基本不超过100页。  
这就是设定了边界条件。  

#### 案例2：雪崩效应的处理
涉及一个灾难应急机制，简单说就是 降级服务，有损服务。  
出现类似问题的时候，系统自动降级，将部分用户请求频次低，价值低但是系统开销不低的功能或者数据临时阻断停止响应，确保整体系统的稳定性。  

#### 案例3：关于主从分离同步的案例
这个案例很好玩，我们刚开始做数据库主从读写分离的时候，经验也不是很丰富，然后发现一个问题，主从同步经常会有一个时延，虽然时间很短，大部分在1秒以内，但是在应用中，我们发现，用户发一个帖子，然后发完后就应该进入这个帖子的展示页吧，帖子发布到主数据库，而展示页调用的是从数据库，结果部分用户发完帖子，因为延迟，就看到了一个该帖子不存在的界面，这肯定是一个不好的情况么。当然，技术上肯定有各种解决方法，比如对这种新内容选择从主数据库访问，做一些标定等等，但是呢，我们就做了一个特别偷懒取巧的方案。什么方案呢？用户发完帖子后，先进入一个中转页，告诉用户您的帖子发布成功，3秒后自动进入帖子页。（对这个场景很多人都熟悉吧），就这么一个特简单甚至有点不是很友好的设计，主从同步延迟的问题就基本解决了。  
这不是一个完美方案，但是简单有效，而且对用户来说，虽然体验略有不好，但其实也不会有非常大的困扰。 当然，今天，我不推荐这样的方案，但是小团队，创业公司，遇到一些比较头疼的技术问题，其实完全可以通过需求的一点点微调就绕开，我希望分享的是这个观点。

### [如何应对并发(4) - 分布式数据库及反范式设计](http://mp.weixin.qq.com/s?__biz=MzI0MjA1Mjg2Ng==&mid=400528497&idx=1&sn=6b068d924ba06d030bbb5b147265abfa&scene=0#wechat_redirect)

#### 基本认识

1. 用分库&拆表是解决数据库容量问题的唯一途径。

2. 分库&拆表也是解决性能压力的最优选择。

3. 分库 – 不同的数据表放到不同的数据库服务器中（也可能是虚拟服务器）

4. 拆表 – 一张数据表拆成多张数据表，可能位于同一台服务器，也可能位于多台服务器（含虚拟服务器）。

#### 去关联化原则
1. 摘除数据表之间的关联，是分库的基础工作。  
2. 摘除关联的目的是，当数据表分布到不同服务器时，查询请求容易分发和处理。  
3. 学会理解反范式数据结构设计，所谓反范式，第一要点是不用外键，不允许Join操作，不允许任何需要跨越两个表的查询请求。第二要点是适度冗余减少查询请求，比如说，信息表，fromuid, touid, message字段外，还需要一个fromuname字段记录用户名，这样查询者通过touid查询后，能够立即得到发信人的用户名，而无需进行另一个数据表的查询。  
4.去关联化处理会带来额外的考虑，比如说，某一个数据表内容的修改，对另一个数据表的影响。这一点需要在程序或其他途径去考虑。

#### 分库方案
1. 安全性拆分:将高安全性数据与低安全性数据分库
2. 基于业务逻辑拆分
3. 基于负载压力拆分
4. 混合拆分组合

#### 分表方案
1. 数据量过大或者访问压力过大的数据表需要切分
2. 纵向分表（常见为忙闲分表）
 * 单数据表字段过多，可将频繁更新的整数数据与非频繁更新的字符串数据切分: 范例 user表 ，个人简介，地址，QQ号，联系方式，头像 这些字段为字符串类型，更新请求少； 最后登录时间，在线时常，访问次数，信件数这些字段为整数型字段，更新频繁，可以将后面这些更新频繁的字段独立拆出一张数据表，表内容变少，索引结构变少，读写请求变快。
3. 横向切表
 * **等分切表**，如哈希切表或其他基于对某数字取余的切表。等分切表的优点是负载很方便的分布到不同服务器；缺点是当容量继续增加时无法方便的扩容，需要重新进行数据的切分或转表。而且一些关键主键不易处理。
 * **递增切表**，比如每1kw用户开一个新表，优点是可以适应数据的自增趋势；缺点是往往新数据负载高，压力分配不平均。
 * **日期切表**，适用于日志记录式数据，优缺点等同于递增切表。
4. 热点数据分表
 * 将数据量较大的数据表中将读写频繁的数据抽取出来，形成热点数据表

#### 反范式设计（冗余结构设计）
1. 基于查询的冗余设计
2. 基于统计的冗余结构:为了减少会涉及大规模影响结果集的表数据操作，比如count，sum操作。应将一些统计类数据通过冗余数据结构保存。
3. 历史数据表

### [如何应对并发(5) - 关键的关键，是认识负载](http://mp.weixin.qq.com/s?__biz=MzI0MjA1Mjg2Ng==&mid=401014185&idx=1&sn=66850ac473e63c639448103066682dc7&scene=23&srcid=1229tdiFjj3d83SXmfRpMLBb#rd)

#### 负载的构成
1. CPU开销是多少，是哪些进程和服务占用的。
2. 内存开销是多少，是哪些进程和服务占用的，如果内存占用了swap分区，大量的硬盘虚拟内存操作，效率自然会直线下降。
3. I/O开销 是多少，读请求的频率，写请求的频率，什么服务和什么操作占用了大量的i/o。
4. 连接数是多少，是怎么分布的，比如http链接多少，数据库链接多少，memcache链接多少，当然更细致的三次握手的链接是多少。
了解这些，是优化的基础，这些都不清楚，谈个毛优化方案。

#### 负载增长趋势
随着应用请求的增加，你的系统的负载是怎么增加的。
1. 线性增加，就是请求两倍，负载变成两倍
2. 指数增加，请求两倍，负载变成四倍甚至更多，
有人会奇怪，为什么这样呢？因为请求增加和数据量增加很可能是一致的，比如一个毫无索引的遍历查询，数据量增加了一倍，查询效率就降低50%，请求量又增加1倍，所以负载就增加了4倍。 这种就是非常不合理的技术架构。
3. 收敛增加，随着你的请求增加规模，负载的增加低于线性增加并逐步收敛，比如说，大量使用缓存和异步更新，请求越多，缓存命中率越高，异步更新的请求合并率越高，这样负载的增加就呈现为收敛性，这样系统的支撑性就会很强大。

#### 系统阈值
很多时候，我们系统出现瓶颈，并不是因为负载很高，而是因为某个请求规模超越了系统阈值，导致无法应答请求。
典型范例如
1. syn flood攻击时，最大的syn连接池被占满
2. http链接数越界，http链接超时设置较长
3. mysql链接数越界，大量使用常链接或不释放链接

#### 峰谷的规律和预测
负载和请求并非一条平顺的曲线，每天都有波峰和波谷，如果有大的活动或市场推广计划，很可能也会有一条非常陡峭的增加曲线。
这时候需要运营者有一个预测和判断，知道波峰在什么时候会发生，而且要知道相关的规律是什么。

#### 异常的监控和跟踪
对各种异常敏感，很多严重的性能问题其实是有先兆的，比如偶尔的501错误，偶尔的访问卡顿，偶尔的链接出错，很多时候，用户刷新一下，这个问题就没有了，但是很可能此事系统已经进入了一个不稳定的状态
有经验和有意识的架构师或运维专家，应该会做日志的跟踪和审计，随时查看这种错误信息的出现频率，并对此进行持续的跟踪监控，在高并发的真实环境中，在一定比例内，这样的偶发异常是非常难免

## 构建高性能WEB站点-郭欣
### 第1章 绪论
#### 1.2 瓶颈在哪里
#### 1.3 增加带宽
#### 1.4 减少网页中的HTTP请求
浏览器缓存

#### 1.5 加快服务器脚本计算速度
Web服务器缓存
反向代理缓存

#### 1.6 使用动态内容缓存
##### 缓存如何存储
##### 缓存命中率如何
##### 缓存过期策略如何设计
##### 分布式缓存设计

#### 1.7 使用数据缓存
#### 1.8 将动态内容静态化
#### 1.9 更换Web服务器软件
#### 1.10 页面组件分离
* 什么组件需要分离
* 如何分离
 * 使用不同的域名
这里的Web组件是指基于URL访问的资源,如动态内容,图片,JavaScript脚本,CSS等  
从以下几个方面来看这些组件的差异:
* 文件大小
* 文件数量
* 内容更新频率
* 预计并发用户数
* 是否需要脚本解释器
* 是否涉及大量CPU计算
* 是否访问数据库
* 访问数据库的主要操作是读还是写
* 是否包含远程调用RPC

对不同的组件采取以下不同的优化方法:
* 是否使用epoll模型
* 是否使用sendfile()系统调用
* 是否使用异步I/O
* 是否支持HTTP持久连接(HTTP Keep-alive)
* 是否需要opcode缓存
* 是否使用动态内容缓存以及有效期为多长
* 是否使用Web服务器缓存以及有效期为多长
* 是否使用浏览器缓存以及有效期为多长
* 是否使用反向代理缓存以及有效期为多长
* 是否使用负载均衡策略

#### 1.11 合理部署服务器
#### 1.12 使用负载均衡
##### HTTP重定向
##### DNS负载均衡
##### 反向代理负载均衡
##### IP负载均衡
##### 直接路由
##### IP隧道

#### 1.13 优化数据库
#### 1.14 考虑可扩展性
#### 1.15 减少视觉等待

## 大网站技术架构-李智慧
### 1 大型网站架构演化
1. 初始阶段的网站架构
2. 应用服务和数据服务分离
3. 使用缓存改善网站性能
4. 使用应用服务器集群改善网站的并发处理能力
5. 数据库读写分离
6. 使用反向代理和CDN加速网站响应
7. 使用分布式文件系统和分布式数据库系统
8. 使用NoSQL和搜索引擎
9. 业务拆分
10. 分布式服务

### 2 网站架构模式
#### 分层
分层   | 作用
----- | ---
应用层 | 负责具体业务和视图展示,如网站首页及搜索输入和结果展示
服务层 | 为应用层提供服务支持,如用户管理服务,购物车服务等
数据层 | 提供数据存储访问服务,如数据库,缓存,文件,搜索引擎等

#### 分割
将不同功能和服务分割开,包装成高内聚低耦合的模块单元,一方便便于开发维护,另一方面便于分布式部署,提高网站的并发处理能力和功能扩展能力  
比如在应用层,将不同业务进行分割,例如将购物,论坛,搜索,广告分割成不同的应用,由独立团队负责,部署在不同的服务器上;在同一个应用内部,可以继续分割,比如购物业务,可以进一步分割成机票酒店业务,3C业务,小商品业务等更细小的粒度.而即使在这个粒度上,还是可以继续分割成首页,搜索列表,商品详情等模块,这些模块不管在逻辑上还是物理部署上,都可以是独立的

#### 分布式
#### 集群
#### 缓存
#### 异步
#### 冗余
#### 自动化
#### 安全

### 4 瞬时响应:网站的高性能架构
#### 4.2 Web前端性能优化
##### 4.2.1 浏览器访问优化
1. 减少HTTP请求
方法主要是合并CSS,合并JavaScript,合并图片,如果每张图片都有不同的超链接,可通过CSS偏移响应鼠标点击操作,构造不同的URL
2. 使用浏览器缓存
3. 启用压缩
4. CSS放在页面最上面,JavaScript放在最下面
5. 减少Cookie传输

##### 4.2.2 CDN加速
##### 4.2.3 反向代理

#### 4.3 应用服务器性能优化
##### 4.3.1 分布式缓存
##### 4.3.2 异步操作
##### 4.3.3 使用集群
##### 4.3.4 代码优化

#### 4.4 存储性能优化
##### 4.4.1 机械硬盘 vs. 固态硬盘
##### 4.4.2 B+树 vs. LSM树
##### 4.4.3 RAID vs. HDFS

#### 4.5 小结
技术是为业务服务的,技术选型和架构决策依赖业务乃至企业战略规划,离开业务发展的支撑和驱动,技术走不远,甚至还会迷路.  
前沿技术总是出现在前沿业务领域.

### 5 万无一失:网站的高可用架构
#### 5.2 高可用的网站架构
#### 5.3 高可用的应用
##### 5.3.1 通过负载均衡进行无状态服务的失效转移
##### 5.3.2 应用服务器集群的Session管理
#### 5.4 高可用的服务
#### 5.5 高可用的数据
##### 5.5.1 CAP原理 (Consistency一致性,Availability可用性,Partition tolerance分区容错性)
1. 数据强一致
2. 数据用户一致
3. 数据最终一致

##### 5.5.2 数据备份
##### 5.5.3 失效转移
#### 5.6 高可用网站的软件质量保证
##### 5.6.1 网站发布
##### 5.6.2 自动化测试
##### 5.6.3 预发布验证
##### 5.6.4 代码控制
##### 5.6.5 自动化发布
##### 5.6.6 灰度发布
#### 5.7 网站运行监控

### 6 永无止境:网站的伸缩性架构
#### 6.1 网站架构的伸缩性设计
##### 6.1.1 不同功能进行物理分离实现伸缩
##### 6.1.2 单一功能通过集群规模实现伸缩
#### 6.2 应用服务器集群的伸缩性设计
##### 6.2.1 HTTP重定向负载均衡
##### 6.2.2 DNS域名解析负载均衡
##### 6.2.3 反向代理负载均衡
##### 6.2.4 IP负载均衡
##### 6.2.5 数据链路层负载均衡
##### 6.2.6 负载均衡算法
1. 轮询 (Round Robin, RR)
2. 加权轮询 (Weighted Round Robin, WRR)
3. 随机 (Random)
4. 最少连接 (Least Connections)
5. 源地址散列 (Source Hashing)

#### 6.3 分布式缓存集群的伸缩性设计
##### 6.3.1 Memcached分布式缓存集群
##### 6.3.3 分布式缓存的一致性Hash算法

### 7 随需应变:网站的可扩展架构
#### 7.2 利用分布式消息队列降低系统耦合性
##### 7.2.1 事件驱动架构 (Event Driven Architecture)
生产者消费者模式

#### 7.3 利用分布式服务打造可复用的业务平台
网站应用系统	用户后台应用系统	交易应用系统	增值业务应用系统 新增业务1应用系统
用户服务		商品服务			店铺服务		库存服务		评价服务
消息队列服务	数据库服务	搜索引擎服务	分布式缓存服务	分布式文件系统服务

##### 7.3.3 分布式服务框架设计
Facebook的Thrift, 阿里的Dubbo

#### 7.4 可扩展的数据结构
#### 7.5 利用开放平台建设网站生态圈


## 高性能服务器架构思路
http://wetest.qq.com/lab/view/?id=80

###  缓存策略的概念和实例
当我们访问一个服务器时，出现服务卡住不能得到数据，就会认为是“性能问题”
但实际上这个性能问题可能有不同原因，表现出来都是针对客户请求的延迟很长甚至中断。原因有哪些：
第一个是所谓并发数不足，也就是同时请求的客户过多，导致超过容纳能力的客户被拒绝服务，这种情况往往会因为服务器内存耗尽而导致的；
第二个是处理延迟过长，也就是有一些客户的请求处理时间已经超过用户可以忍受的长度，这种情况常常表现为CPU占用满额100%。

服务器开发的时候，最常用到的有下面这几种硬件：CPU、内存、磁盘、网卡。
其中CPU是代表计算机处理时间的，硬盘的空间一般很大，主要是读写磁盘会带来比较大的处理延迟，而内存、网卡则是受存储、带宽的容量限制的。所以当我们的服务器出现性能问题的时候，就是这几个硬件某一个甚至几个都出现负荷占满的情况。
这四个硬件的资源一般可以抽象成两类：
一类是时间资源，比如CPU和磁盘读写；
一类是空间资源，比如内存和网卡带宽。
所以当我们的服务器出现性能问题，有一个最基本的思路，就是**时间空间转换**  

空间换时间:
1. 文件内容长时间的保存在内存中,另外一个对同样文件的读取时直接从内存中把数据返回给客户端，无需去磁盘读取
2. 用内存把静态数据一次性读取并保存起来，这样每次读这些数据，都和数据库无关;每次变化的写操作都先去写内存，然后定期写回到数据库，这样把多次写数据库操作变成一次写操作  

时间换空间:
1. 企业通讯录的数据存储系统要保存下通讯录的每次新增、修改、删除操作，也就是这个数据的所有变更历史，以便可以让数据回退到任何一个过去的时间点
最简单的做法，就是这个数据在任何变化的时候，都拷贝一份副本。但是这样会非常的浪费磁盘空间
时间换空间的做法:在每次数据变化的时候，都记下一条记录，内容就是数据变化的情况：插入了一条内容是某某的联系方法、删除了一条某某的联系方法……，这样我们记录的数据，仅仅就是变化的部分，而不需要拷贝很多份副本。当我们需要恢复到任何一个时间点的时候，只需要按这些记录依次对数据修改一遍，直到指定的时间点的记录即可。这个恢复的时间可能会有点长，但是却可以大大节省存储空间。这就是用CPU的时间来换磁盘的存储空间的策略
2. 现在常见的MySQL InnoDB日志型数据表，以及SVN源代码存储，都是使用这种策略的
3. Web服务器在发送HTML，往往也会先用ZIP压缩，然后发送给浏览器，浏览器收到后要先解压再显示，这是用服务器和客户端的CPU时间，来换取网络带宽的空间

**缓存的本质**
1. 已经处理过的数据，不需要重复处理
2. 以快速的数据存储读写，代替较慢速的存储读写的策略  

缓存的数据和我们程序真正要操作的数据，往往是需要进行一些拷贝和运算的，这就是序列化和反序列化的过程，这个过程很快，也有可能很慢。所以我们在选择数据缓存结构的时候，必须要注意其转换时间，否则你缓存的效果可能被这些数据拷贝、转换消耗去很多，严重的甚至比不缓存更差

### 缓存策略的难点 缓存清理
两种建立缓存的方法：一是程序一启动，就一股脑把所有的静态数据从文件或者数据库读入内存；二就是程序启动的时候并不加载静态数据，而是等有用户访问相关数据的时候，才去加载，这也就是所谓lazy load的做法.  

第一种方法编程比较简单，程序的内存启动后就稳定了，不太容易出现内存漏洞（如果加载的缓存太多，程序在启动后立刻会因内存不足而退出，比较容易发现问题）；第二种方法程序启动很快，但要对缓存占用的空间有所限制或者规划，否则如果要缓存的数据太多，可能会耗尽内存，导致在线服务中断。

解决这类问题有两种处理策略：
1. 使用控制命令。简单来说，就是在服务器进程上，开通一个实时的命令端口
2. 使用字段判断逻辑。在每次读取缓存前，根据一些特征数据，快速的判断内存中的缓存和源数据内容，是否有不一致（是否脏）的地方，如果有不一致的地方，就自动清理这条数据的缓存

#### “冷热交换”策略
设计缓存的结构时，就应该构建一个可以统计缓存读写次数的指标，如果有些数据的读写频率过低，或者空闲（没有人读、写缓存）时间超长，缓存应该主动清理掉这些数据，以便其他新的数据能进入缓存。这种策略也叫做“冷热交换”策略。实现“冷热交换”的策略时，关键是要定义一个合理的冷热统计算法。一些固定的指标和算法，往往并不能很好的应对不同硬件、不同网络情况下的变化，所以现在人们普遍会用一些动态的算法.  

仔细研究需要缓存的数据特征。然后最大化的利用业务领域的知识，来设计最合理的缓存清理策略。这个世界上不存在万能的优化缓存清理策略，只存在针对业务领域最优化的策略，这需要我们程序员深入理解业务领域，去发现数据背后的规律。

### 分布策略的概念

## 性能优化
1. 响应时间（RT）
2. 吐出量（QPS/TPS） Query Per Second / Transactions PerSecond
3. 资源（CPU、线程等）

### 理解响应时间组成
通常是通过埋点的方式把代码执行切分成一段一段的片段，获取各个节点、各类节点的消耗，用于观察性能情况，定位性能瓶颈点；链路上的埋点，可以配合监控系统统一来看，阿里是自己实现了一个简单的埋点类。

## 性能测试
陈皓 [如何严谨地做性能测试](http://coolshell.cn/articles/17381.html?hmsr=toutiao.io&utm_medium=toutiao.io&utm_source=toutiao.io)

一般来说，性能测试要统一考虑这么几个因素：Thoughput吞吐量，Latency响应时间，资源利用（CPU/MEM/IO/Bandwidth…），成功率，系统稳定性。

下面的这些性能测试的方式基本上来源自我的老老东家汤森路透，一家做real-time的金融数据系统的公司。

一，你得定义一个系统的响应时间latency，建议是TP99，以及成功率。比如路透的定义：99.9%的响应时间必需在1ms之内，平均响应时间在1ms以内，100%的请求成功。

二，在这个响应时间的限制下，找到最高的吞吐量。测试用的数据，需要有大中小各种尺寸的数据，并可以混合。最好使用生产线上的测试数据。

三，在这个吞吐量做Soak Test，比如：使用第二步测试得到的吞吐量连续7天的不间断的压测系统。然后收集CPU，内存，硬盘/网络IO，等指标，查看系统是否稳定，比如，CPU是平稳的，内存使用也是平稳的。那么，这个值就是系统的性能

四，找到系统的极限值。比如：在成功率100%的情况下（不考虑响应时间的长短），系统能坚持10分钟的吞吐量。

五，做Burst Test。用第二步得到的吞吐量执行5分钟，然后在第四步得到的极限值执行1分钟，再回到第二步的吞吐量执行5钟，再到第四步的权限值执行1分钟，如此往复个一段时间，比如2天。收集系统数据：CPU、内存、硬盘/网络IO等，观察他们的曲线，以及相应的响应时间，确保系统是稳定的。

六、低吞吐量和网络小包的测试。有时候，在低吞吐量的时候，可能会导致latency上升，比如TCP_NODELAY的参数没有开启会导致latency上升（详见TCP的那些事），而网络小包会导致带宽用不满也会导致性能上不去，所以，性能测试还需要根据实际情况有选择的测试一下这两咱场景。

（注：在路透，路透会用第二步得到的吞吐量乘以66.7%来做为系统的软报警线，80%做为系统的硬报警线，而极限值仅仅用来扛突发的peak）

##  聊聊高并发系统之限流特技
张开涛
[聊聊高并发系统之限流特技](https://mp.weixin.qq.com/s?__biz=MzI3MzEzMDI1OQ==&mid=2651814677&idx=1&sn=66c30a97fc1325d500c3b204886df404&scene=23&srcid=0715Ui77nWOgIjUwPciHGylb#rd)

在开发高并发系统时有三把利器用来保护系统：缓存、降级和限流
缓存的目的是提升系统访问速度和增大系统能处理的容量
降级是当服务出问题或者影响到核心流程的性能则需要暂时屏蔽掉，待高峰或者问题解决后再打开
有些场景并不能用缓存和降级来解决，比如稀缺资源（秒杀、抢购）、写服务（如评论、下单）、频繁的复杂查询（评论的最后几页），因此需有一种手段来限制这些场景的并发/请求量，即限流

限流的目的是通过对并发访问/请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务（定向到错误页或告知资源没有了）、排队或等待（比如秒杀、评论、下单）、降级（返回兜底数据或默认数据，如商品详情页库存默认有货）
一般都会采用IP级别的限流，即针对某一个IP，限制单位时间内发起请求数量。
有损服务　　最后一招，在接近前端池承载能力的水位上限的时候，随机拒绝部分请求来保护活动整体的可用性。

常见的限流有：
1. 限制总并发数（比如数据库连接池、线程池）、
2. 限制瞬时并发数（如nginx的limit_conn模块，用来限制瞬时并发连接数）、
3. 限制时间窗口内的平均速率（如Guava的RateLimiter、nginx的limit_req模块，限制每秒的平均速率）；
4. 其他还有如限制远程接口调用速率、限制MQ的消费速率。
5. 另外还可以根据网络连接数、网络流量、CPU或内存负载等来限流。

### 应用级限流
限流总并发/连接/请求数

对于一个应用系统来说一定会有极限并发/请求数，即总有一个TPS/QPS阀值，如果超了阀值则系统就会不响应用户请求或响应的非常慢，因此我们最好进行过载保护，防止大量请求涌入击垮系统
Tomcat，其Connector 其中一种配置有如下几个参数
* `acceptCount`：如果Tomcat的线程都忙于响应，新来的连接会进入队列排队，如果超出排队大小，则拒绝连接；
* `maxConnections`： 瞬时最大连接数，超出的会排队等待；
* `maxThreads`：Tomcat能启动用来处理请求的最大线程数，如果请求处理量一直远远大于最大线程数则可能会僵死。

详细的配置请参考官方文档。另外如Mysql（如max_connections）、Redis（如tcp-backlog）都会有类似的限制连接数的配置。

#### 限流某个接口的总并发/请求数
因为粒度比较细，可以为每个接口都设置相应的阀值。可以使用Java中的AtomicLong进行限流, 但这种方式简单粗暴的限流，没有平滑处理，需要根据实际情况选择使用

``` java

	try {
	    if(atomic.incrementAndGet() > 限流数) {
	        //拒绝请求
	    }
	    //处理请求
	} finally {
	    atomic.decrementAndGet();
	}
```
