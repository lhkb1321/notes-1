[TOC]

#High performance Notes

## I/O

I/O有内存I/O,网络I/O和磁盘I/O,在讨论Web站点性能时很少提及内存I/O,国为相比后两种I/O操作,内存I/O的速度已经够快了,性能瓶颈往往并不在于内存I/O.  
以文件I/O为例,一个I/O读过程: 数据从磁盘(网卡) -> 内核缓冲区 -> 用户内存. 同步与异步的区别主要在于数据从内核缓冲区 -> 用户内存这个过程需不需要用户进程等待.

* 同步阻塞
* 同步非阻塞
* I/O多路复用 select/poll/epoll
* 信号驱动 sigio
* 异步非阻塞

### 阻塞与非阻塞,同步与异步
阻塞和非阻塞是指当前进程访问的数据如果尚未就绪,进程是否需要等待,简单说相当于函数内部的实现区别,即未就绪时是直接返回还是等待就绪  
同步和异步是指访问数据的机制  
	同步指主动请求并等待I/O操作完毕的方式,当数据就绪后在读写的时候必须阻塞.  
	异步指主动请求数据后便可以继续处理其他任务,随后等待IO操作完毕的通知,这可以使进程在数据读写时也不发生阻塞.

### 同步阻塞I/O
同步阻塞I/O是指当进程调用某些涉及I/O操作的系统调用或库函数时,比如accept(),send(),recv()等,进程便停下来,等待I/O操作完成后继续运行. 这是一种简单而有效的I/O模型,它可以和多进程结合起来有效地利用CPU资源,但是代价就是多进程的大量内存开销.  
进程实际等待时间 = 等待数据就绪 + 等待数据复制. 对于网络I/O来说,等待就绪的时间会更长.  

**在小吃城吃饭的例子** 在小吃城的小吃店里点了一个面条,然后等着做好,做好后吃完再继续逛街.这里的吃面条便是I/O操作,它要等厨师做面条,还要等自己把面条吃完.

### 同步非阻塞I/O
同步非阻塞I/O的调用不会等待数据的就绪,如果数据不可读或者不可写,它会立即告诉进程. 结合反复轮询来尝试数据是否就绪,防止进程被阻塞,最大的好处便在于可以在一个进程里同时处理多个I/O操作.  
但多次轮询会花费大量的CPU时间,使得进程处于忙碌等待状态

**在小吃城吃饭的例子** 回到买面条的故事,假如你不甘心坐着等面条,想去逛街,可又担心做好后没及时取,所以你逛一会儿便回去看看面条是否做好,往返了很多次,最后及时吃上了面条,但是却累的气喘吁吁

非阻塞I/O一般只针对网络I/O有效,只要在socket的选项设置中使用O_NONBLOCK即可,这样对于该socket的send()或recv()便采用非阻塞方式. 值得注意的是,对于磁盘I/O,非阻塞I/O并不产生效果.

#### 多路I/O就绪通知
多路I/O就绪通知提供了大量文件描述符(File Descriptor, FD)就绪检查的高效方案,它允许进程通过一种方法来同时监视所有FD,并可以获得所有就绪的FD,然后只针对这些FD进行数据访问.

**在小吃城吃饭的例子** 假如你不止买了一份面条,还在其他几个小吃店买了饺子,粥等.这些东西都需要时间来制作.在同步非阻塞I/O模型中,你要轮流不停地去各个小吃店询问进度.现在引入多路I/O就绪通知后,小吃管理处给大厅安装了一块电子屏幕,以后所有小吃店的食物做好后,都会显示在屏幕上,你只需要间隔性地看看大屏幕就可以了,也许你还可以同时逛逛附近的商店,在不远处也可以看到大屏幕.

I/O就绪通知只是快速获得就绪的FD,当得知数据就绪后,就访问数据本身而言,仍然需要选择阻塞或者非阻塞的访问方式,以防止任何意外的等待阻塞整个进程.  
I/O复用的实现方式主要有select,poll和epoll

#### select/poll
select和poll的原理基本相同:
* 注册待侦听的FD
* 每次调用都去检查所有FD的状态,当有一个或者多个FD就绪时就返回
* 返回结果中包括已就绪和未就绪的FD
select的一个缺点在于单个进程能监视的FD的数量存在最大限制,在Linux上一般为1024,不过可以通过修改宏定义甚至重新编译内核的方式提升这一限制.  
poll没有最大FD数量的限制.  
poll和select共同具有的一个很大的缺点是包含大量FD的数组被整体复制于用户态和内核地址空间之间,开销会随着FD数量增多而线性增大.  
优点: select和poll将就绪的FD告诉进程后,如果没有对其进行I/O操作,那么下次调用select或poll的时候将再次报告这些FD,所以它们一般不会丢失就绪的消息,这种方式称为**水平触发(Level Triggered)**  

#### 信号驱动 SIGIO
Linux 2.4提供了SIGIO,它通过实时信号(Real Time Signal)来实现select/poll的通知方法,但它们的不同在于,select/poll告诉我们哪些FD是就绪的,一直到我们读写它之前,每次select/poll都会告诉我们;而SIGIO则是告诉我们哪些FD刚刚变为就绪状态,它只说一遍,如果我们没有采取行动,那么它将不会再次告知,这种方式称为**边缘触发(Edge Triggered)**. 缺点是容易发生事件丢失.  
SIGIO几乎是Linux 2.4下性能最好的多路I/O就绪通知方法.

#### epoll
epoll的出现解决了select/poll的缺点:
1. 基于事件驱动的方式,避免了每次都要把所有FD都扫描一遍
2. `epoll_wait`只返回就绪的文件标识符
3. `epoll`使用nmap内存映射技术避免了内存复制开销  
4. epoll的FD数量上限是操作系统的最大文件句柄数目,这个数据一般和内存有关,通常远大于1024
5. epoll默认使用水平触发,通过相应选项可以使用边缘触发.

目前,epoll是Linux 2.6下最高效的I/O复用方式,也是Nginx,Node的I/O实现方式.

**在小吃城吃饭的例子** 虽然有了电子屏幕,但是显示的内容是所有餐品的状态,包括正在制作的和已经做好的,这显然造成了阅读上的麻烦,就好像select/poll每次返回所有监视的文件描述符一样.如果能只显示做好的餐品,那该多好,随后小吃城管理处改进并实现了这一点.这就像/dev/poll一样只告知就绪的文件描述符.在显示做好的餐点时,如果只显示一次,而不管你有没有看到,这就相当于边缘触发,而如果在你领取餐点之前,每次都显示,就相当于水平触发.  
但尽管这样,一旦你走的比较远,就还得花时间走到小吃城去看电子屏幕,能不能让你更加轻松地获得通知呢?管理处这次采用了手机短信通知的方法,你只需要到管理处注册后,便可以在餐点就绪时及时收到短信通知,这类似于epoll的事件机制.

#### 内存映射 Memory Mapping
Linux内核提供的一种访问磁盘文件的特殊方式,它可以将内存中某块地址空间和我们要指定的磁盘文件相关联,从而把我们对这块内存的访问转换为对磁盘文件的访问,这种技术称为内存映射.  
多数情况下,使用内存映射可以提高磁盘I/O的性能,像访问内存一样自由的访问文件.

#### 直接I/O
数据访问过程 磁盘 -> 内核缓冲区 -> 用户态内存空间
有一些应用(如数据库服务器)为了充分提高性能,希望绕过内核缓冲区,由自己在用户态空间实现并管理I/O缓冲区,包括缓存机制和写延迟机制等.

### 异步I/O 异步非阻塞
对比信号驱动IO，异步IO的主要区别在于：信号驱动由内核告诉我们何时可以开始一个IO操作(数据在内核缓冲区中)，而异步IO则由内核通知IO操作何时已经完成(数据已经在用户空间中)。  
异步IO又叫做事件驱动IO，在Unix中，POSIX1003.1标准为异步方式访问文件定义了一套库函数，定义了AIO的一系列接口。使用`aio_read`或者`aio_write`发起异步IO操作。使用`aio_error`检查正在运行的IO操作的状态。

**在小吃城吃饭的例子** 之前的就餐方式，到最后总是需要你自己去把饭菜端到餐桌。这下你也不耐烦了，于是就告诉老板，能不能饭好了直接端到你的面前或者送到你的家里(外卖)。这就是异步非阻塞IO了。  

### Java I/O
上文讲述了UNIX环境的五种IO模型。基于这五种模型，在Java中，随着NIO和NIO2.0(AIO)的引入，一般具有三种网络编程模型：BIO,NIO,AIO

#### BIO
BIO是一个典型的网络编程模型，是通常我们实现一个服务端程序的过程，步骤如下：
1. 主线程accept请求阻塞
2. 请求到达，创建新的线程来处理这个套接字，完成对客户端的响应。
3. 主线程继续accept下一个请求
这种模型有一个很大的问题是：当客户端连接增多时，服务端创建的线程也会暴涨，系统性能会急剧下降。因此，在此模型的基础上，类似于 tomcat的bio connector，采用的是线程池来避免对于每一个客户端都创建一个线程。有些地方把这种方式叫做伪异步IO(把请求抛到线程池中异步等待处理)。

#### NIO
JDK1.4开始引入了NIO类库，这里的NIO指的是Non-block IO，主要是使用Selector多路复用器来实现。Selector在Linux等主流操作系统上是通过epoll实现的。
NIO的实现流程，类似于select：
1. 创建ServerSocketChannel监听客户端连接并绑定监听端口，设置为非阻塞模式。
2. 创建Reactor线程，创建多路复用器(Selector)并启动线程。
3. 将ServerSocketChannel注册到Reactor线程的Selector上。监听accept事件。
4. Selector在线程run方法中无线循环轮询准备就绪的Key。
5. Selector监听到新的客户端接入，处理新的请求，完成TCP三次握手，建立物理连接。
6. 将新的客户端连接注册到Selector上，监听读操作。读取客户端发送的网络消息。
7. 客户端发送的数据就绪则读取客户端请求，进行处理。
相比BIO，NIO的编程非常复杂。

#### AIO
JDK1.7引入NIO2.0，提供了异步文件通道和异步套接字通道的实现，是真正的异步非阻塞I/O, 对应于Unix中的异步I/O。
1. 创建AsynchronousServerSocketChannel，绑定监听端口
2. 调用AsynchronousServerSocketChannel的accept方法，传入自己实现的CompletionHandler。包括上一步，都是非阻塞的
3. 连接传入，回调CompletionHandler的completed方法，在里面，调用AsynchronousSocketChannel的read方法，传入负责处理数据的CompletionHandler。
4. 数据就绪，触发负责处理数据的CompletionHandler的completed方法。继续做下一步处理即可。
5. 写入操作类似，也需要传入CompletionHandler。
其编程模型相比NIO有了不少的简化。

#### 对比
对比				|	同步阻塞IO	|	伪异步IO	|	NIO		|	AIO
----|---
客户端数目 IO线程	| 	1 : 1 		|	m : n	|	m : 1	|	m : 0
IO模型 			|	同步阻塞IO	|同步阻塞IO 	|同步非阻塞IO |异步非阻塞IO
吞吐量 			|	低 			|	中		| 	高		| 	高
编程复杂度 		| 	简单 		|	简单 	|非常复杂 	|	复杂


## 缓存
##### 缓存如何存储
##### 缓存命中率如何
##### 缓存过期策略如何设计
##### 分布式缓存设计

## 分布式多线程

## 如何应对并发
转自　曹政 caoz的梦呓
### [如何应对并发(1) - 关于数据索引](http://mp.weixin.qq.com/s?__biz=MzI0MjA1Mjg2Ng==&mid=400470606&idx=1&sn=eff5350f80190ad6e32659f434aac970&scene=0#wechat_redirect)

#### 经典案例1，大翻页问题
#### 经典案例2，积分排行问题

#### 如何评估SQL的执行开销
索引中遍历的记录越少，效率越高，遍历的记录越多，效率越差。 在慢查询日志或者explain分析中，一个重要的指标是 affected rows，（好像也有别的叫法，不查证了，大家应该能知道我说的是什么），这个就是索引遍历的记录说，我以前硬翻译叫做影响结果集，我后来看其他人写的数据库文档叫索引扫描行数，概念是一样的。

高性能ＭySQL
explain SQL
去数据库里，先show processlist;看到有疑问的SQL，去explain，然后set profiling=1

### [如何应对并发(2) - 请求合并及异步处理](http://mp.weixin.qq.com/s?__biz=MzI0MjA1Mjg2Ng==&mid=400480069&idx=1&sn=4119397d0e3b0444f04d25f76ecdfbe3&scene=0#wechat_redirect)

#### 并不是查询请求缓存化了系统效率就会提升
1、如果缓存命中率不高，可能反而是负担  
2、如果缓存计不合理，系统开销只会更高  
3、雪崩效应的风险  

#### 慢查询日志肯定是要看的
第一，看查询和更新的比例。
第二，看最多查询的数据表有哪些，最多更新的数据表有哪些。
第三，看最多查询的数据表最多查询的SQL是什么样子的，最多更新的数据表最多执行更新的SQL是怎样的，算出各自每秒的请求频率。
第四，关键分析，最多查询的SQL，基于同一主键查询的比例多不多（潜台词，可以缓存化）。最多更新的SQL，基于同一主键的更新的比例高不高（潜台词，可以合并请求，异步处理，当然必须根据具体业务诉求再核对一遍）
首先用眼睛看日志找规律，其次基于规律用grep 来统计。 然后把内容整理后，询问相关的程序员，每条问题SQL的业务逻辑是什么，然后毕竟还是要让他们一线的程序员来评估业务逻辑上这些操作是否可以合并，缓存，或者异步处理

### [如何应对并发(3) - 需求裁剪](http://mp.weixin.qq.com/s?__biz=MzI0MjA1Mjg2Ng==&mid=400516974&idx=1&sn=66a65b0900a8a410b7268d4b9c7bbddb&scene=0#wechat_redirect)

#### 案例1：搜索大翻页问题，还记得我提过的这个搜索翻页越多，负载越高的问题么。
请问，  
淘宝搜索一个关键词，最多翻多少页？百度呢？google呢？  
你们自行测试一下，这些巨头给出的搜索结果条目数，我跟你们实话说，都是估算值，最大翻页数，基本不超过100页。  
这就是设定了边界条件。  

#### 案例2：雪崩效应的处理
涉及一个灾难应急机制，简单说就是 降级服务，有损服务。  
出现类似问题的时候，系统自动降级，将部分用户请求频次低，价值低但是系统开销不低的功能或者数据临时阻断停止响应，确保整体系统的稳定性。  

#### 案例3：关于主从分离同步的案例
这个案例很好玩，我们刚开始做数据库主从读写分离的时候，经验也不是很丰富，然后发现一个问题，主从同步经常会有一个时延，虽然时间很短，大部分在1秒以内，但是在应用中，我们发现，用户发一个帖子，然后发完后就应该进入这个帖子的展示页吧，帖子发布到主数据库，而展示页调用的是从数据库，结果部分用户发完帖子，因为延迟，就看到了一个该帖子不存在的界面，这肯定是一个不好的情况么。当然，技术上肯定有各种解决方法，比如对这种新内容选择从主数据库访问，做一些标定等等，但是呢，我们就做了一个特别偷懒取巧的方案。什么方案呢？用户发完帖子后，先进入一个中转页，告诉用户您的帖子发布成功，3秒后自动进入帖子页。（对这个场景很多人都熟悉吧），就这么一个特简单甚至有点不是很友好的设计，主从同步延迟的问题就基本解决了。  
这不是一个完美方案，但是简单有效，而且对用户来说，虽然体验略有不好，但其实也不会有非常大的困扰。 当然，今天，我不推荐这样的方案，但是小团队，创业公司，遇到一些比较头疼的技术问题，其实完全可以通过需求的一点点微调就绕开，我希望分享的是这个观点。

### [如何应对并发(4) - 分布式数据库及反范式设计](http://mp.weixin.qq.com/s?__biz=MzI0MjA1Mjg2Ng==&mid=400528497&idx=1&sn=6b068d924ba06d030bbb5b147265abfa&scene=0#wechat_redirect)

#### 基本认识

1. 用分库&拆表是解决数据库容量问题的唯一途径。

2. 分库&拆表也是解决性能压力的最优选择。

3. 分库 – 不同的数据表放到不同的数据库服务器中（也可能是虚拟服务器）

4. 拆表 – 一张数据表拆成多张数据表，可能位于同一台服务器，也可能位于多台服务器（含虚拟服务器）。

#### 去关联化原则
1. 摘除数据表之间的关联，是分库的基础工作。  
2. 摘除关联的目的是，当数据表分布到不同服务器时，查询请求容易分发和处理。  
3. 学会理解反范式数据结构设计，所谓反范式，第一要点是不用外键，不允许Join操作，不允许任何需要跨越两个表的查询请求。第二要点是适度冗余减少查询请求，比如说，信息表，fromuid, touid, message字段外，还需要一个fromuname字段记录用户名，这样查询者通过touid查询后，能够立即得到发信人的用户名，而无需进行另一个数据表的查询。  
4.去关联化处理会带来额外的考虑，比如说，某一个数据表内容的修改，对另一个数据表的影响。这一点需要在程序或其他途径去考虑。

#### 分库方案
1. 安全性拆分:将高安全性数据与低安全性数据分库
2. 基于业务逻辑拆分
3. 基于负载压力拆分
4. 混合拆分组合

#### 分表方案
1. 数据量过大或者访问压力过大的数据表需要切分
2. 纵向分表（常见为忙闲分表）
 * 单数据表字段过多，可将频繁更新的整数数据与非频繁更新的字符串数据切分: 范例 user表 ，个人简介，地址，QQ号，联系方式，头像 这些字段为字符串类型，更新请求少； 最后登录时间，在线时常，访问次数，信件数这些字段为整数型字段，更新频繁，可以将后面这些更新频繁的字段独立拆出一张数据表，表内容变少，索引结构变少，读写请求变快。
3. 横向切表 
 * **等分切表**，如哈希切表或其他基于对某数字取余的切表。等分切表的优点是负载很方便的分布到不同服务器；缺点是当容量继续增加时无法方便的扩容，需要重新进行数据的切分或转表。而且一些关键主键不易处理。
 * **递增切表**，比如每1kw用户开一个新表，优点是可以适应数据的自增趋势；缺点是往往新数据负载高，压力分配不平均。
 * **日期切表**，适用于日志记录式数据，优缺点等同于递增切表。
4. 热点数据分表
 * 将数据量较大的数据表中将读写频繁的数据抽取出来，形成热点数据表
 
#### 反范式设计（冗余结构设计）
1. 基于查询的冗余设计
2. 基于统计的冗余结构:为了减少会涉及大规模影响结果集的表数据操作，比如count，sum操作。应将一些统计类数据通过冗余数据结构保存。
3. 历史数据表

### [如何应对并发(5) - 关键的关键，是认识负载](http://mp.weixin.qq.com/s?__biz=MzI0MjA1Mjg2Ng==&mid=401014185&idx=1&sn=66850ac473e63c639448103066682dc7&scene=23&srcid=1229tdiFjj3d83SXmfRpMLBb#rd)

#### 负载的构成
1. CPU开销是多少，是哪些进程和服务占用的。
2. 内存开销是多少，是哪些进程和服务占用的，如果内存占用了swap分区，大量的硬盘虚拟内存操作，效率自然会直线下降。
3. I/O开销 是多少，读请求的频率，写请求的频率，什么服务和什么操作占用了大量的i/o。
4. 连接数是多少，是怎么分布的，比如http链接多少，数据库链接多少，memcache链接多少，当然更细致的三次握手的链接是多少。
了解这些，是优化的基础，这些都不清楚，谈个毛优化方案。

#### 负载增长趋势
随着应用请求的增加，你的系统的负载是怎么增加的。
1. 线性增加，就是请求两倍，负载变成两倍
2. 指数增加，请求两倍，负载变成四倍甚至更多，
有人会奇怪，为什么这样呢？因为请求增加和数据量增加很可能是一致的，比如一个毫无索引的遍历查询，数据量增加了一倍，查询效率就降低50%，请求量又增加1倍，所以负载就增加了4倍。 这种就是非常不合理的技术架构。
3. 收敛增加，随着你的请求增加规模，负载的增加低于线性增加并逐步收敛，比如说，大量使用缓存和异步更新，请求越多，缓存命中率越高，异步更新的请求合并率越高，这样负载的增加就呈现为收敛性，这样系统的支撑性就会很强大。

#### 系统阈值
很多时候，我们系统出现瓶颈，并不是因为负载很高，而是因为某个请求规模超越了系统阈值，导致无法应答请求。
典型范例如
1. syn flood攻击时，最大的syn连接池被占满
2. http链接数越界，http链接超时设置较长
3. mysql链接数越界，大量使用常链接或不释放链接

#### 峰谷的规律和预测
负载和请求并非一条平顺的曲线，每天都有波峰和波谷，如果有大的活动或市场推广计划，很可能也会有一条非常陡峭的增加曲线。
这时候需要运营者有一个预测和判断，知道波峰在什么时候会发生，而且要知道相关的规律是什么。

#### 异常的监控和跟踪
对各种异常敏感，很多严重的性能问题其实是有先兆的，比如偶尔的501错误，偶尔的访问卡顿，偶尔的链接出错，很多时候，用户刷新一下，这个问题就没有了，但是很可能此事系统已经进入了一个不稳定的状态
有经验和有意识的架构师或运维专家，应该会做日志的跟踪和审计，随时查看这种错误信息的出现频率，并对此进行持续的跟踪监控，在高并发的真实环境中，在一定比例内，这样的偶发异常是非常难免

## 构建高性能WEB站点-郭欣
### 第1章 绪论
#### 1.2 瓶颈在哪里
#### 1.3 增加带宽
#### 1.4 减少网页中的HTTP请求
浏览器缓存

#### 1.5 加快服务器脚本计算速度
Web服务器缓存
反向代理缓存

#### 1.6 使用动态内容缓存
##### 缓存如何存储
##### 缓存命中率如何
##### 缓存过期策略如何设计
##### 分布式缓存设计

#### 1.7 使用数据缓存
#### 1.8 将动态内容静态化
#### 1.9 更换Web服务器软件
#### 1.10 页面组件分离
* 什么组件需要分离
* 如何分离
 * 使用不同的域名
这里的Web组件是指基于URL访问的资源,如动态内容,图片,JavaScript脚本,CSS等  
从以下几个方面来看这些组件的差异:
* 文件大小
* 文件数量
* 内容更新频率
* 预计并发用户数
* 是否需要脚本解释器
* 是否涉及大量CPU计算
* 是否访问数据库
* 访问数据库的主要操作是读还是写
* 是否包含远程调用RPC

对不同的组件采取以下不同的优化方法:
* 是否使用epoll模型
* 是否使用sendfile()系统调用
* 是否使用异步I/O
* 是否支持HTTP持久连接(HTTP Keep-alive)
* 是否需要opcode缓存
* 是否使用动态内容缓存以及有效期为多长
* 是否使用Web服务器缓存以及有效期为多长
* 是否使用浏览器缓存以及有效期为多长
* 是否使用反向代理缓存以及有效期为多长
* 是否使用负载均衡策略

#### 1.11 合理部署服务器
#### 1.12 使用负载均衡
##### HTTP重定向
##### DNS负载均衡
##### 反向代理负载均衡
##### IP负载均衡
##### 直接路由
##### IP隧道

#### 1.13 优化数据库
#### 1.14 考虑可扩展性
#### 1.15 减少视觉等待

## 大网站技术架构-李智慧
### 1 大型网站架构演化
1. 初始阶段的网站架构
2. 应用服务和数据服务分离
3. 使用缓存改善网站性能
4. 使用应用服务器集群改善网站的并发处理能力
5. 数据库读写分离
6. 使用反向代理和CDN加速网站响应
7. 使用分布式文件系统和分布式数据库系统
8. 使用NoSQL和搜索引擎
9. 业务拆分
10. 分布式服务

### 2 网站架构模式
#### 分层
分层   | 作用
----- | ---
应用层 | 负责具体业务和视图展示,如网站首页及搜索输入和结果展示
服务层 | 为应用层提供服务支持,如用户管理服务,购物车服务等
数据层 | 提供数据存储访问服务,如数据库,缓存,文件,搜索引擎等

#### 分割
将不同功能和服务分割开,包装成高内聚低耦合的模块单元,一方便便于开发维护,另一方面便于分布式部署,提高网站的并发处理能力和功能扩展能力  
比如在应用层,将不同业务进行分割,例如将购物,论坛,搜索,广告分割成不同的应用,由独立团队负责,部署在不同的服务器上;在同一个应用内部,可以继续分割,比如购物业务,可以进一步分割成机票酒店业务,3C业务,小商品业务等更细小的粒度.而即使在这个粒度上,还是可以继续分割成首页,搜索列表,商品详情等模块,这些模块不管在逻辑上还是物理部署上,都可以是独立的

#### 分布式
#### 集群
#### 缓存
#### 异步
#### 冗余
#### 自动化
#### 安全

### 4 瞬时响应:网站的高性能架构
#### 4.2 Web前端性能优化
##### 4.2.1 浏览器访问优化
1. 减少HTTP请求
方法主要是合并CSS,合并JavaScript,合并图片,如果每张图片都有不同的超链接,可通过CSS偏移响应鼠标点击操作,构造不同的URL
2. 使用浏览器缓存
3. 启用压缩
4. CSS放在页面最上面,JavaScript放在最下面
5. 减少Cookie传输

##### 4.2.2 CDN加速
##### 4.2.3 反向代理

#### 4.3 应用服务器性能优化
##### 4.3.1 分布式缓存
##### 4.3.2 异步操作
##### 4.3.3 使用集群
##### 4.3.4 代码优化

#### 4.4 存储性能优化
##### 4.4.1 机械硬盘 vs. 固态硬盘
##### 4.4.2 B+树 vs. LSM树
##### 4.4.3 RAID vs. HDFS

#### 4.5 小结
技术是为业务服务的,技术选型和架构决策依赖业务乃至企业战略规划,离开业务发展的支撑和驱动,技术走不远,甚至还会迷路.  
前沿技术总是出现在前沿业务领域.
 
### 5 万无一失:网站的高可用架构
#### 5.2 高可用的网站架构
#### 5.3 高可用的应用
##### 5.3.1 通过负载均衡进行无状态服务的失效转移
##### 5.3.2 应用服务器集群的Session管理
#### 5.4 高可用的服务
#### 5.5 高可用的数据
##### 5.5.1 CAP原理 (Consistency一致性,Availability可用性,Partition tolerance分区容错性)
1. 数据强一致
2. 数据用户一致
3. 数据最终一致

##### 5.5.2 数据备份
##### 5.5.3 失效转移
#### 5.6 高可用网站的软件质量保证
##### 5.6.1 网站发布
##### 5.6.2 自动化测试
##### 5.6.3 预发布验证
##### 5.6.4 代码控制
##### 5.6.5 自动化发布
##### 5.6.6 灰度发布
#### 5.7 网站运行监控

### 6 永无止境:网站的伸缩性架构
#### 6.1 网站架构的伸缩性设计
##### 6.1.1 不同功能进行物理分离实现伸缩
##### 6.1.2 单一功能通过集群规模实现伸缩
#### 6.2 应用服务器集群的伸缩性设计
##### 6.2.1 HTTP重定向负载均衡
##### 6.2.2 DNS域名解析负载均衡
##### 6.2.3 反向代理负载均衡
##### 6.2.4 IP负载均衡
##### 6.2.5 数据链路层负载均衡
##### 6.2.6 负载均衡算法
1. 轮询 (Round Robin, RR)
2. 加权轮询 (Weighted Round Robin, WRR)
3. 随机 (Random)
4. 最少连接 (Least Connections)
5. 源地址散列 (Source Hashing)

#### 6.3 分布式缓存集群的伸缩性设计
##### 6.3.1 Memcached分布式缓存集群
##### 6.3.3 分布式缓存的一致性Hash算法

### 7 随需应变:网站的可扩展架构
#### 7.2 利用分布式消息队列降低系统耦合性
##### 7.2.1 事件驱动架构 (Event Driven Architecture)
生产者消费者模式

#### 7.3 利用分布式服务打造可复用的业务平台
网站应用系统	用户后台应用系统	交易应用系统	增值业务应用系统 新增业务1应用系统
用户服务		商品服务			店铺服务		库存服务		评价服务
消息队列服务	数据库服务	搜索引擎服务	分布式缓存服务	分布式文件系统服务

##### 7.3.3 分布式服务框架设计
Facebook的Thrift, 阿里的Dubbo

#### 7.4 可扩展的数据结构
#### 7.5 利用开放平台建设网站生态圈
