[TOC]

#High performance Notes

## 如何应对并发
转自　曹政 caoz的梦呓
### [如何应对并发(1) - 关于数据索引](http://mp.weixin.qq.com/s?__biz=MzI0MjA1Mjg2Ng==&mid=400470606&idx=1&sn=eff5350f80190ad6e32659f434aac970&scene=0#wechat_redirect)

#### 经典案例1，大翻页问题
#### 经典案例2，积分排行问题

#### 如何评估SQL的执行开销
索引中遍历的记录越少，效率越高，遍历的记录越多，效率越差。 在慢查询日志或者explain分析中，一个重要的指标是 affected rows，（好像也有别的叫法，不查证了，大家应该能知道我说的是什么），这个就是索引遍历的记录说，我以前硬翻译叫做影响结果集，我后来看其他人写的数据库文档叫索引扫描行数，概念是一样的。

高性能ＭySQL
explain SQL
去数据库里，先show processlist;看到有疑问的SQL，去explain，然后set profiling=1

### [如何应对并发(2) - 请求合并及异步处理](http://mp.weixin.qq.com/s?__biz=MzI0MjA1Mjg2Ng==&mid=400480069&idx=1&sn=4119397d0e3b0444f04d25f76ecdfbe3&scene=0#wechat_redirect)

#### 并不是查询请求缓存化了系统效率就会提升
1、如果缓存命中率不高，可能反而是负担  
2、如果缓存设计不合理，系统开销只会更高  
3、雪崩效应的风险  

#### 慢查询日志肯定是要看的
第一，看查询和更新的比例。
第二，看最多查询的数据表有哪些，最多更新的数据表有哪些。
第三，看最多查询的数据表最多查询的SQL是什么样子的，最多更新的数据表最多执行更新的SQL是怎样的，算出各自每秒的请求频率。
第四，关键分析，最多查询的SQL，基于同一主键查询的比例多不多（潜台词，可以缓存化）。最多更新的SQL，基于同一主键的更新的比例高不高（潜台词，可以合并请求，异步处理，当然必须根据具体业务诉求再核对一遍）
首先用眼睛看日志找规律，其次基于规律用grep 来统计。 然后把内容整理后，询问相关的程序员，每条问题SQL的业务逻辑是什么，然后毕竟还是要让他们一线的程序员来评估业务逻辑上这些操作是否可以合并，缓存，或者异步处理

### [如何应对并发(3) - 需求裁剪](http://mp.weixin.qq.com/s?__biz=MzI0MjA1Mjg2Ng==&mid=400516974&idx=1&sn=66a65b0900a8a410b7268d4b9c7bbddb&scene=0#wechat_redirect)

#### 案例1：搜索大翻页问题，还记得我提过的这个搜索翻页越多，负载越高的问题么。
请问，  
淘宝搜索一个关键词，最多翻多少页？百度呢？google呢？  
你们自行测试一下，这些巨头给出的搜索结果条目数，我跟你们实话说，都是估算值，最大翻页数，基本不超过100页。  
这就是设定了边界条件。  

#### 案例2：雪崩效应的处理
涉及一个灾难应急机制，简单说就是 降级服务，有损服务。  
出现类似问题的时候，系统自动降级，将部分用户请求频次低，价值低但是系统开销不低的功能或者数据临时阻断停止响应，确保整体系统的稳定性。  

#### 案例3：关于主从分离同步的案例
这个案例很好玩，我们刚开始做数据库主从读写分离的时候，经验也不是很丰富，然后发现一个问题，主从同步经常会有一个时延，虽然时间很短，大部分在1秒以内，但是在应用中，我们发现，用户发一个帖子，然后发完后就应该进入这个帖子的展示页吧，帖子发布到主数据库，而展示页调用的是从数据库，结果部分用户发完帖子，因为延迟，就看到了一个该帖子不存在的界面，这肯定是一个不好的情况么。当然，技术上肯定有各种解决方法，比如对这种新内容选择从主数据库访问，做一些标定等等，但是呢，我们就做了一个特别偷懒取巧的方案。什么方案呢？用户发完帖子后，先进入一个中转页，告诉用户您的帖子发布成功，3秒后自动进入帖子页。（对这个场景很多人都熟悉吧），就这么一个特简单甚至有点不是很友好的设计，主从同步延迟的问题就基本解决了。  
这不是一个完美方案，但是简单有效，而且对用户来说，虽然体验略有不好，但其实也不会有非常大的困扰。 当然，今天，我不推荐这样的方案，但是小团队，创业公司，遇到一些比较头疼的技术问题，其实完全可以通过需求的一点点微调就绕开，我希望分享的是这个观点。

### [如何应对并发(4) - 分布式数据库及反范式设计](http://mp.weixin.qq.com/s?__biz=MzI0MjA1Mjg2Ng==&mid=400528497&idx=1&sn=6b068d924ba06d030bbb5b147265abfa&scene=0#wechat_redirect)

#### 分库方案
1. 安全性拆分:将高安全性数据与低安全性数据分库
2. 基于业务逻辑拆分
3. 基于负载压力拆分
4. 混合拆分组合

#### 分表方案
1. 数据量过大或者访问压力过大的数据表需要切分
2. 纵向分表（常见为忙闲分表）
 * 单数据表字段过多，可将频繁更新的整数数据与非频繁更新的字符串数据切分: 范例 user表 ，个人简介，地址，QQ号，联系方式，头像 这些字段为字符串类型，更新请求少； 最后登录时间，在线时常，访问次数，信件数这些字段为整数型字段，更新频繁，可以将后面这些更新频繁的字段独立拆出一张数据表，表内容变少，索引结构变少，读写请求变快。
3. 横向切表 
 * **等分切表**，如哈希切表或其他基于对某数字取余的切表。等分切表的优点是负载很方便的分布到不同服务器；缺点是当容量继续增加时无法方便的扩容，需要重新进行数据的切分或转表。而且一些关键主键不易处理。
 * **递增切表**，比如每1kw用户开一个新表，优点是可以适应数据的自增趋势；缺点是往往新数据负载高，压力分配不平均。
 * **日期切表**，适用于日志记录式数据，优缺点等同于递增切表。
4. 热点数据分表
 * 将数据量较大的数据表中将读写频繁的数据抽取出来，形成热点数据表
 
#### 反范式设计（冗余结构设计）
1. 基于查询的冗余设计
2. 基于统计的冗余结构:为了减少会涉及大规模影响结果集的表数据操作，比如count，sum操作。应将一些统计类数据通过冗余数据结构保存。
3. 历史数据表

### [如何应对并发(5) - 关键的关键，是认识负载](http://mp.weixin.qq.com/s?__biz=MzI0MjA1Mjg2Ng==&mid=401014185&idx=1&sn=66850ac473e63c639448103066682dc7&scene=23&srcid=1229tdiFjj3d83SXmfRpMLBb#rd)

#### 负载的构成
1. CPU开销是多少，是哪些进程和服务占用的。
2. 内存开销是多少，是哪些进程和服务占用的，如果内存占用了swap分区，大量的硬盘虚拟内存操作，效率自然会直线下降。
3. I/O开销 是多少，读请求的频率，写请求的频率，什么服务和什么操作占用了大量的i/o。
4. 连接数是多少，是怎么分布的，比如http链接多少，数据库链接多少，memcache链接多少，当然更细致的三次握手的链接是多少。
了解这些，是优化的基础，这些都不清楚，谈个毛优化方案。

#### 负载增长趋势
随着应用请求的增加，你的系统的负载是怎么增加的。
1. 线性增加，就是请求两倍，负载变成两倍
2. 指数增加，请求两倍，负载变成四倍甚至更多，
有人会奇怪，为什么这样呢？因为请求增加和数据量增加很可能是一致的，比如一个毫无索引的遍历查询，数据量增加了一倍，查询效率就降低50%，请求量又增加1倍，所以负载就增加了4倍。 这种就是非常不合理的技术架构。
3. 收敛增加，随着你的请求增加规模，负载的增加低于线性增加并逐步收敛，比如说，大量使用缓存和异步更新，请求越多，缓存命中率越高，异步更新的请求合并率越高，这样负载的增加就呈现为收敛性，这样系统的支撑性就会很强大。

#### 系统阈值
很多时候，我们系统出现瓶颈，并不是因为负载很高，而是因为某个请求规模超越了系统阈值，导致无法应答请求。
典型范例如
1. syn flood攻击时，最大的syn连接池被占满
2. http链接数越界，http链接超时设置较长
3. mysql链接数越界，大量使用常链接或不释放链接

#### 峰谷的规律和预测
负载和请求并非一条平顺的曲线，每天都有波峰和波谷，如果有大的活动或市场推广计划，很可能也会有一条非常陡峭的增加曲线。
这时候需要运营者有一个预测和判断，知道波峰在什么时候会发生，而且要知道相关的规律是什么。

#### 异常的监控和跟踪
对各种异常敏感，很多严重的性能问题其实是有先兆的，比如偶尔的501错误，偶尔的访问卡顿，偶尔的链接出错，很多时候，用户刷新一下，这个问题就没有了，但是很可能此事系统已经进入了一个不稳定的状态
有经验和有意识的架构师或运维专家，应该会做日志的跟踪和审计，随时查看这种错误信息的出现频率，并对此进行持续的跟踪监控，在高并发的真实环境中，在一定比例内，这样的偶发异常是非常难免