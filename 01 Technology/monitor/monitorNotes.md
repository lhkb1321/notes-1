
# Monitor Notes

## 分布式调用跟踪系统的设计和应用学习
邴越 [链接](https://yq.aliyun.com/articles/58408)

随着服务的拆分，系统的模块变得越来越多，不同的模块可能由不同的团队维护，一个请求可能会涉及到几十个服务的协同处理， 牵扯到多个团队的业务系统，那么如何快速准确的定位到线上故障？  
同时，缺乏一个自上而下全局的调用id，如何有效的进行相关的数据分析工作？  
比较成熟的解决方案是 **通过调用链的方式，把一次请求调用过程完整的串联起来，这样就实现了对请求调用路径的监控。**
### 调用跟踪系统的业务场景
* 故障快速定位
  通过调用链跟踪，一次请求的逻辑轨迹可以用完整清晰的展示出来。  
  开发中可以在业务日志中添加调用链ID，可以通过调用链结合业务日志快速定位错误信息。
* 各个调用环节的性能分析
  在调用链的各个环节分别添加调用时延，可以分析系统的性能瓶颈，进行针对性的优化。
* 各个调用环节的可用性，持久层依赖等
  通过分析各个环节的平均时延，QPS等信息，可以找到系统的薄弱环节，对一些模块做调整，如数据冗余等。
* 数据分析等
  调用链是一条完整的业务日志，可以得到用户的行为路径，汇总分析应用在很多业务场景。

### 分布式调用跟踪系统的设计
#### 目标
* 低侵入性，应用透明
* 低损耗
* 大范围部署，扩展性

#### 埋点和生成日志
通常包含：
1. TraceId、RPCId、调用的开始时间，调用类型，协议类型，调用方ip和端口，请求的服务名等信息；
2. 调用耗时，调用结果，异常信息，消息报文等；
3. 预留可扩展字段，为下一步扩展做准备；

#### 抓取和存储日志
一般来说，会使用离线+实时的方式去存储日志，主要是分布式日志采集的方式。典型的解决方案如Flume结合Kafka等MQ。
#### 分析和统计调用链数据
一条调用链的日志散落在调用经过的各个服务器上，首先需要按 TraceId 汇总日志，然后按照RpcId 对调用链进行顺序整理。  
调用链数据不要求百分之百准确，可以允许中间的部分日志丢失
#### 计算和展示
汇总得到各个应用节点的调用链日志后，可以针对性的对各个业务线进行分析。  
需要对具体日志进行整理，进一步储存在HBase或者关系型数据库中，可以进行可视化的查询。

### 调用跟踪系统的选型 Distributed Systems Tracing
大的互联网公司都有自己的分布式跟踪系统，比如Google的Dapper，Twitter的zipkin，淘宝的鹰眼，新浪的Watchman，京东的Hydra等

#### Google的Drapper
[Dapper, a Large-Scale Distributed Systems Tracing Infrastructure](http://research.google.com/pubs/pub36356.html)
[简要总结](http://duanple.blog.163.com/blog/static/70971767201329113141336/)
[完整译文](https://bigbully.github.io/Dapper-translation/)
Dapper是Google生产环境下的分布式跟踪系统，Dapper有三个设计目标：

* 低消耗：跟踪系统对在线服务的影响应该做到足够小。
* 应用级的透明：对于应用的程序员来说，是不需要知道有跟踪系统这回事的。如果一个跟踪系统想生效，就必须需要依赖应用的开发者主动配合，那么这个跟踪系统显然是侵入性太强的。
* 延展性：Google至少在未来几年的服务和集群的规模，监控系统都应该能完全把控住。

Drapper的日志格式：  
dapper用span来表示一个服务调用开始和结束的时间，也就是时间区间。
dapper记录了span的名称以及每个span的ID和父ID，如果一个span没有父ID被称之为root span。所有的span都挂在一个特定的trace上，共用一个traceID，这些ID用全局64位整数标示。
